{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c592c93e",
   "metadata": {},
   "source": [
    "# Etape 1 - Exploration et chargement Spark\n",
    "\n",
    "**Objectif** : Charger et explorer les donnees de qualite de l'air avec PySpark\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665f965",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e12c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd003451",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4288ba",
   "metadata": {},
   "source": [
    "## Chemins des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5056ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = (Path.cwd() / \"..\" / \"data\").resolve()\n",
    "AIR_QUALITY_PATH = os.path.join(DATA_DIR, \"air_quality_raw.csv\")\n",
    "STATIONS_PATH = os.path.join(DATA_DIR, \"stations.csv\")\n",
    "WEATHER_PATH = os.path.join(DATA_DIR, \"weather_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec06c36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c369fe",
   "metadata": {},
   "source": [
    "## 1.1 Création d'une session Spark locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916290be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.7\n",
      "Spark UI: http://joel:4040\n"
     ]
    }
   ],
   "source": [
    "## Creer une session Spark locale\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TP Qualite Air - Exploration\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "## Reduire les logs\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "## Affichage de l'actuelle version de Spark & de l'url de Spark UI\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da106d23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e3ddf",
   "metadata": {},
   "source": [
    "## 1.2 Chargement du fichier air_quality_raw.csv en DataFrame Spark (les données de la qualité de l'air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac7c5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fichier de la qualité de l'air 'air_quality_raw.csv' a été chargé avec succès.\n",
      "- Nombre de lignes : 1230951\n",
      "- Nombre de colonnes : 5\n",
      "- Apercu des donnees :\n",
      "+----------+-------------------+---------+-----+-----+\n",
      "|station_id|timestamp          |pollutant|value|unit |\n",
      "+----------+-------------------+---------+-----+-----+\n",
      "|ST0040    |2024-01-07T05:00:00|O3       |79.29|ug/m3|\n",
      "|ST0004    |06/09/2024 18:00:00|O3       |41.58|ug/m3|\n",
      "|ST0027    |2024-05-23 11:00:00|PM10     |29.20|ug/m3|\n",
      "|ST0002    |18/03/2024 12:00   |SO2      |7.72 |ug/m3|\n",
      "|ST0035    |2024-06-11T08:00:00|O3       |29.87|ug/m3|\n",
      "|ST0023    |19/04/2024 10:00   |O3       |30.07|ug/m3|\n",
      "|ST0035    |19/03/2024 05:00   |PM2.5    |14.12|ug/m3|\n",
      "|ST0001    |2024-05-19T13:00:00|PM10     |17,09|ug/m3|\n",
      "|ST0014    |10/03/2024 20:00   |CO       |0.29 |mg/m3|\n",
      "|ST0004    |2024-01-28T16:00:00|NO2      |25,69|ug/m3|\n",
      "+----------+-------------------+---------+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Chargement du CSV avec inference de schema\n",
    "df_air_raw = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(AIR_QUALITY_PATH)\n",
    "\n",
    "print(\"- Fichier de la qualité de l'air 'air_quality_raw.csv' a été chargé avec succès.\")\n",
    "\n",
    "## Information sur le nombre de lignes et de colonnes\n",
    "print(\"- Nombre de lignes :\", df_air_raw.count())\n",
    "print(\"- Nombre de colonnes :\", len(df_air_raw.columns))\n",
    "\n",
    "## Apercu des donnees\n",
    "print(\"- Apercu des donnees :\")\n",
    "df_air_raw.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79422bd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439abe8",
   "metadata": {},
   "source": [
    "## 1.3 Affichage du schéma inféré et identification des problèmes de typage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb79d18",
   "metadata": {},
   "source": [
    "### 1.3.1 Affichage du schéma inféré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c63bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- pollutant: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- unit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_air_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13406f9a",
   "metadata": {},
   "source": [
    "### 1.3.2 Identification des problèmes de typage\n",
    "- **timestamp**\n",
    "\n",
    "la colonne ``timestamp`` est en string car Il y'a differents formats de timestamp :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96353ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de formats de timestamp:\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2024-01-07T05:00:00|\n",
      "|2024-05-19T13:00:00|\n",
      "|05/26/2024 14:00:00|\n",
      "|2024-04-12T09:00:00|\n",
      "|2024-01-31T14:00:00|\n",
      "|2024-06-02 20:00:00|\n",
      "|05/18/2024 07:00:00|\n",
      "|2024-04-26T22:00:00|\n",
      "|2024-03-31T02:00:00|\n",
      "|28/04/2024 22:00   |\n",
      "|2024-03-22 10:00:00|\n",
      "|2024-04-02 00:00:00|\n",
      "|2024-03-30 18:00:00|\n",
      "|16/03/2024 02:00   |\n",
      "|04/22/2024 22:00:00|\n",
      "|03/03/2024 02:00:00|\n",
      "|2024-06-28 11:00:00|\n",
      "|12/05/2024 12:00   |\n",
      "|17/01/2024 03:00   |\n",
      "|2024-03-28T08:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemples de formats de timestamp:\")\n",
    "df_air_raw.select(\"timestamp\").distinct().show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f608d",
   "metadata": {},
   "source": [
    "- **value**\n",
    "\n",
    "La colonne ``value`` est en string également car elle contient des valeurs avec des virgules et des valeurs textuelles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f3da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Nombre de valeurs non numeriques : 6,076\n",
      "- Differents valeurs non numeriques :\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "| null|\n",
      "|  N/A|\n",
      "|error|\n",
      "|  ---|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Les valeurs qui ne peuvent pas etre converties en nombre\n",
    "df_non_numeric = df_air_raw.filter(\n",
    "    ~F.col(\"value\").rlike(\"^-?[0-9]+[.,]?[0-9]*$\")\n",
    ")\n",
    "\n",
    "print(f\"- Nombre de valeurs non numeriques : {df_non_numeric.count():,}\")\n",
    "\n",
    "print(f\"- Differents valeurs non numeriques :\")\n",
    "df_non_numeric.select(\"value\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac51dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Nombre de valeurs avec virgule : 184,556\n",
      "- Exemples :\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|17,09|\n",
      "|25,69|\n",
      "|15,42|\n",
      "|29,14|\n",
      "|12,82|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Valeurs avec virgule comme separateur decimal\n",
    "df_with_comma = df_air_raw.filter(F.col(\"value\").contains(\",\"))\n",
    "print(f\"- Nombre de valeurs avec virgule : {df_with_comma.count():,}\")\n",
    "\n",
    "## Affichages d'exemples\n",
    "print(f\"- Exemples :\")\n",
    "df_with_comma.select(\"value\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29db83",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e6f41",
   "metadata": {},
   "source": [
    "## 1.4 Calcul des statistiques descriptives par polluant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6988ea",
   "metadata": {},
   "source": [
    "Initialement on a la colonne ``value`` en string. \n",
    "\n",
    "Pour calculer les statistiques descriptives, on va créer une dataFrame 'df_air_numeric' qui contient les mêmes données que 'df_air_raw' plus une colonne 'value_clean' qui contient les valeurs de la colonne 'value_clean' converties en double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05800e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Apercu de la df_air_numeric :\n",
      "+----------+-------------------+---------+-----+-----+-----------+\n",
      "|station_id|          timestamp|pollutant|value| unit|value_clean|\n",
      "+----------+-------------------+---------+-----+-----+-----------+\n",
      "|    ST0040|2024-01-07T05:00:00|       O3|79.29|ug/m3|      79.29|\n",
      "|    ST0004|06/09/2024 18:00:00|       O3|41.58|ug/m3|      41.58|\n",
      "|    ST0027|2024-05-23 11:00:00|     PM10|29.20|ug/m3|       29.2|\n",
      "|    ST0002|   18/03/2024 12:00|      SO2| 7.72|ug/m3|       7.72|\n",
      "|    ST0035|2024-06-11T08:00:00|       O3|29.87|ug/m3|      29.87|\n",
      "|    ST0023|   19/04/2024 10:00|       O3|30.07|ug/m3|      30.07|\n",
      "|    ST0035|   19/03/2024 05:00|    PM2.5|14.12|ug/m3|      14.12|\n",
      "|    ST0001|2024-05-19T13:00:00|     PM10|17,09|ug/m3|      17.09|\n",
      "|    ST0014|   10/03/2024 20:00|       CO| 0.29|mg/m3|       0.29|\n",
      "|    ST0004|2024-01-28T16:00:00|      NO2|25,69|ug/m3|      25.69|\n",
      "+----------+-------------------+---------+-----+-----+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "- Nombre des valeurs Nulls dans la colonne 'value_clean' : 6076\n",
      "\n",
      "- Statistiques par polluant (en ignorant les valeurs nulles) :\n",
      "+---------+------+------+------+-------+-------+------+\n",
      "|pollutant| count|  mean|stddev|    min|    max|median|\n",
      "+---------+------+------+------+-------+-------+------+\n",
      "|       CO|204062| 33.71|341.16|  -2.57|4996.48|  0.71|\n",
      "|      NO2|204093| 78.09|336.51|-163.48|4998.69| 42.43|\n",
      "|       O3|204220|108.78|337.01|-269.95|4999.37| 70.52|\n",
      "|     PM10|204133|  70.1|335.05|-132.57|4999.15| 35.25|\n",
      "|    PM2.5|204189| 55.31|336.76| -81.23|4999.69| 21.18|\n",
      "|      SO2|204178| 40.73|342.75| -26.57|4997.95|  7.05|\n",
      "+---------+------+------+------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Nombre des valeurs Nulls initiales dans df_air_raw\n",
    "df_air_raw.filter(F.col(\"value\").isNull()).count()\n",
    "\n",
    "## Ajouter de la colonne 'value_clean' dans la dataFrame df_air_raw\n",
    "## & convertion de value en double (en remplacant la virgule par un point)\n",
    "df_air_numeric = df_air_raw.withColumn(\n",
    "    \"value_clean\",\n",
    "    F.regexp_replace(F.col(\"value\"), \",\", \".\").cast(\"double\")\n",
    ")\n",
    "\n",
    "## Apercu de la df_air_numeric\n",
    "print(\"- Apercu de la df_air_numeric :\")\n",
    "df_air_numeric.show(10)\n",
    "\n",
    "## Nombre des valeurs Nulls dans df_air_numeric\n",
    "print(\"- Nombre des valeurs Nulls dans la colonne 'value_clean' :\", df_air_numeric.filter(F.col(\"value_clean\").isNull()).count())\n",
    "\n",
    "## Calcul des statistiques descriptives par polluant (en ignorant les valeurs nulles de 'value_clean')\n",
    "stats_by_pollutant = df_air_numeric.filter(F.col(\"value_clean\").isNotNull()) \\\n",
    "    .groupBy(\"pollutant\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round(F.mean(\"value_clean\"), 2).alias(\"mean\"),\n",
    "        F.round(F.stddev(\"value_clean\"), 2).alias(\"stddev\"),\n",
    "        F.round(F.min(\"value_clean\"), 2).alias(\"min\"),\n",
    "        F.round(F.max(\"value_clean\"), 2).alias(\"max\"),\n",
    "        F.round(F.expr(\"percentile(value_clean, 0.5)\"), 2).alias(\"median\")\n",
    "    ) \\\n",
    "    .orderBy(\"pollutant\")\n",
    "\n",
    "print(\"\\n- Statistiques par polluant (en ignorant les valeurs nulles) :\")\n",
    "stats_by_pollutant.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f0071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Valeurs negatives:\n",
      "+---------+-----+\n",
      "|pollutant|count|\n",
      "+---------+-----+\n",
      "|      SO2| 2018|\n",
      "|       O3| 2062|\n",
      "|      NO2| 2033|\n",
      "|     PM10| 2040|\n",
      "|       CO| 2087|\n",
      "|    PM2.5| 2070|\n",
      "+---------+-----+\n",
      "\n",
      "- Valeurs > 1000 ug/m3:\n",
      "+---------+-----+\n",
      "|pollutant|count|\n",
      "+---------+-----+\n",
      "|      SO2| 2066|\n",
      "|       O3| 2080|\n",
      "|      NO2| 2031|\n",
      "|     PM10| 2017|\n",
      "|       CO| 2070|\n",
      "|    PM2.5| 2063|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Identification des valeurs aberrantes\n",
    "print(\"- Valeurs negatives:\")\n",
    "df_air_numeric.filter(F.col(\"value_clean\") < 0).groupBy(\"pollutant\").count().show()\n",
    "\n",
    "print(\"- Valeurs > 1000 ug/m3:\")\n",
    "df_air_numeric.filter(F.col(\"value_clean\") > 1000).groupBy(\"pollutant\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed2011",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663cb240",
   "metadata": {},
   "source": [
    "## 1.5 Comptage des valeurs nulles par colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09bda4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Nombre de valeurs nulles/vides par colonne:\n",
      "+----------+---------+---------+-----+----+\n",
      "|station_id|timestamp|pollutant|value|unit|\n",
      "+----------+---------+---------+-----+----+\n",
      "|         0|        0|        0|    0|   0|\n",
      "+----------+---------+---------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_counts = df_air_raw.select([\n",
    "    F.count(F.when(F.col(c).isNull() | (F.col(c) == \"\"), c)).alias(c)\n",
    "    for c in df_air_raw.columns\n",
    "])\n",
    "\n",
    "print(\"- Nombre de valeurs nulles/vides par colonne:\")\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41434f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae0b315",
   "metadata": {},
   "source": [
    "## 1.6 Identification des stations avec le plus d'enregistrements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa352e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Les stations ids avec le plus d'enregistrements :\n",
      "+----------+----------------------+\n",
      "|station_id|nbre_d_enregistrements|\n",
      "+----------+----------------------+\n",
      "|    ST0032|                 26264|\n",
      "|    ST0012|                 26244|\n",
      "|    ST0028|                 26241|\n",
      "|    ST0003|                 26239|\n",
      "|    ST0029|                 26235|\n",
      "|    ST0024|                 26235|\n",
      "|    ST0020|                 26235|\n",
      "|    ST0037|                 26233|\n",
      "|    ST0023|                 26233|\n",
      "|    ST0042|                 26224|\n",
      "+----------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## station ids avec le plus d'enregistrements (affichage par ordre décroissant du nombre des enregistrements)\n",
    "print(\"- Les stations ids avec le plus d'enregistrements :\")\n",
    "df_stations_enregistrements_count = df_air_raw.groupBy('station_id').count().withColumnRenamed(\"count\", \"nbre_d_enregistrements\").orderBy(F.col(\"count\").desc())\n",
    "df_stations_enregistrements_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec3e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fichier de des stations 'stations.csv' a été chargé avec succès.\n",
      "- Nombre de lignes : 47\n",
      "- Nombre de colonnes : 6\n",
      "- Apercu des donnees :\n",
      "+----------+------------------------+---------+---------+--------+------------+\n",
      "|station_id|station_name            |city     |lat      |lon     |station_type|\n",
      "+----------+------------------------+---------+---------+--------+------------+\n",
      "|ST0001    |Paris-urbaine-1         |Paris    |48.809101|2.329703|urbaine     |\n",
      "|ST0002    |Paris-periurbaine-2     |Paris    |48.828921|2.375847|periurbaine |\n",
      "|ST0003    |Paris-industrielle-3    |Paris    |48.87427 |2.391418|industrielle|\n",
      "|ST0004    |Lyon-urbaine-1          |Lyon     |45.773049|4.788878|urbaine     |\n",
      "|ST0005    |Lyon-periurbaine-2      |Lyon     |45.72337 |4.808966|periurbaine |\n",
      "|ST0006    |Lyon-industrielle-3     |Lyon     |45.774202|4.841825|industrielle|\n",
      "|ST0007    |Marseille-urbaine-1     |Marseille|43.288452|5.364721|urbaine     |\n",
      "|ST0008    |Marseille-periurbaine-2 |Marseille|43.274319|5.40673 |periurbaine |\n",
      "|ST0009    |Marseille-industrielle-3|Marseille|43.322381|5.335766|industrielle|\n",
      "|ST0010    |Marseille-trafic-4      |Marseille|43.288761|5.347587|trafic      |\n",
      "+----------+------------------------+---------+---------+--------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Chargement du CSV des stations avec inference de schema\n",
    "df_stations = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(STATIONS_PATH)\n",
    "\n",
    "print(\"- Fichier de des stations 'stations.csv' a été chargé avec succès.\")\n",
    "\n",
    "## Information sur le nombre de lignes et de colonnes\n",
    "print(\"- Nombre de lignes :\", df_stations.count())\n",
    "print(\"- Nombre de colonnes :\", len(df_stations.columns))\n",
    "\n",
    "## Apercu des donnees\n",
    "print(\"- Apercu des donnees :\")\n",
    "df_stations.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d363347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------+--------------------+----------+---------+---------+------------+\n",
      "|station_id|nbre_d_enregistrements|        station_name|      city|      lat|      lon|station_type|\n",
      "+----------+----------------------+--------------------+----------+---------+---------+------------+\n",
      "|    ST0032|                 26264|Strasbourg-periur...|Strasbourg|48.563516| 7.708719| periurbaine|\n",
      "|    ST0012|                 26244| Marseille-urbaine-6| Marseille|43.256721| 5.357793|     urbaine|\n",
      "|    ST0028|                 26241|Nantes-periurbaine-2|    Nantes|47.267352|  -1.5396| periurbaine|\n",
      "|    ST0003|                 26239|Paris-industrielle-3|     Paris| 48.87427| 2.391418|industrielle|\n",
      "|    ST0029|                 26235|Nantes-industriel...|    Nantes|47.224095|-1.535139|industrielle|\n",
      "|    ST0024|                 26235|Lille-industrielle-3|     Lille|50.646218| 3.077482|industrielle|\n",
      "|    ST0020|                 26235|Bordeaux-periurba...|  Bordeaux|44.816739|-0.621221| periurbaine|\n",
      "|    ST0023|                 26233| Lille-periurbaine-2|     Lille|50.595465| 3.042827| periurbaine|\n",
      "|    ST0037|                 26233|Grenoble-industri...|  Grenoble|45.163163| 5.730637|industrielle|\n",
      "|    ST0042|                 26224| Rouen-periurbaine-2|     Rouen| 49.47931| 1.065184| periurbaine|\n",
      "|    ST0035|                 26221|  Grenoble-urbaine-1|  Grenoble|45.178063| 5.765955|     urbaine|\n",
      "|    ST0015|                 26221|Toulouse-periurba...|  Toulouse|43.608323| 1.491512| periurbaine|\n",
      "|    ST0007|                 26219| Marseille-urbaine-1| Marseille|43.288452| 5.364721|     urbaine|\n",
      "|    ST0044|                 26207|      Rouen-trafic-4|     Rouen|49.452841| 1.088377|      trafic|\n",
      "|    ST0030|                 26204|     Nantes-trafic-4|    Nantes|47.252685|   -1.526|      trafic|\n",
      "|    ST0014|                 26199|  Toulouse-urbaine-1|  Toulouse|43.635413| 1.467173|     urbaine|\n",
      "|    ST0017|                 26199|   Toulouse-trafic-4|  Toulouse| 43.63764| 1.456052|      trafic|\n",
      "|    ST0010|                 26199|  Marseille-trafic-4| Marseille|43.288761| 5.347587|      trafic|\n",
      "|    ST0040|                 26198|  Grenoble-urbaine-6|  Grenoble|45.160432| 5.774254|     urbaine|\n",
      "|    ST0009|                 26198|Marseille-industr...| Marseille|43.322381| 5.335766|industrielle|\n",
      "+----------+----------------------+--------------------+----------+---------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Affichage des stations (avec leurs données) avec le plus d'enregistrements (ordre décroissant)\n",
    "df_stations_enregistrements_count.join(df_stations, on=\"station_id\", how=\"left\").orderBy(F.col(\"nbre_d_enregistrements\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203602dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764594c0",
   "metadata": {},
   "source": [
    "## 1.7 Synthese des problemes de qualite identifies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af2a958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enregistrements : 1,230,951\n",
      "\n",
      "Problemes identifies :\n",
      "  - Valeurs non numeriques: 6,076 (0.49%)\n",
      "  - Valeurs avec virgule decimale: 184,556 (14.99%)\n",
      "  - Valeurs negatives: 12,310 (1.00%)\n",
      "  - Valeurs aberrantes (>1000): 12,327 (1.00%)\n",
      "  - Doublons: 24,136 (1.96%)\n",
      "  - Formats de dates multiples : 4 formats differents detectes\n"
     ]
    }
   ],
   "source": [
    "## Nombre total des enregistrements\n",
    "total_enregistrements = df_air_raw.count()\n",
    "\n",
    "## Valeurs non numeriques\n",
    "non_numeric = df_air_raw.filter(\n",
    "    ~F.col(\"value\").rlike(\"^-?[0-9]+[.,]?[0-9]*$\")\n",
    ").count()\n",
    "\n",
    "## Valeurs avec virgule\n",
    "with_comma = df_air_raw.filter(F.col(\"value\").contains(\",\")).count()\n",
    "\n",
    "## Valeurs negatives (apres conversion)\n",
    "negative = df_air_numeric.filter(F.col(\"value_clean\") < 0).count()\n",
    "\n",
    "## Valeurs aberrantes > 1000\n",
    "outliers = df_air_numeric.filter(F.col(\"value_clean\") > 1000).count()\n",
    "\n",
    "## Doublons\n",
    "duplicates = total_enregistrements - df_air_raw.dropDuplicates([\"station_id\", \"timestamp\", \"pollutant\"]).count()\n",
    "\n",
    "\n",
    "print(f\"Total enregistrements : {total_enregistrements:,}\")\n",
    "print()\n",
    "print(f\"Problemes identifies :\")\n",
    "print(f\"  - Valeurs non numeriques: {non_numeric:,} ({non_numeric/total_enregistrements*100:.2f}%)\")\n",
    "print(f\"  - Valeurs avec virgule decimale: {with_comma:,} ({with_comma/total_enregistrements*100:.2f}%)\")\n",
    "print(f\"  - Valeurs negatives: {negative:,} ({negative/total_enregistrements*100:.2f}%)\")\n",
    "print(f\"  - Valeurs aberrantes (>1000): {outliers:,} ({outliers/total_enregistrements*100:.2f}%)\")\n",
    "print(f\"  - Doublons: {duplicates:,} ({duplicates/total_enregistrements*100:.2f}%)\")\n",
    "print(f\"  - Formats de dates multiples : 4 formats differents detectes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be289e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13be938",
   "metadata": {},
   "source": [
    "## Fermer la session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "275b37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
